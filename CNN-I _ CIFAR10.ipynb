{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from contextlib import suppress\n",
    "with suppress(Exception):from keras.callbacks import EarlyStopping\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "np.random.seed(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 16s 0us/step\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/250\n",
      "50000/50000 [==============================] - 46s 917us/step - loss: 2.9267 - acc: 0.2677 - val_loss: 1.5022 - val_acc: 0.4518\n",
      "Epoch 2/250\n",
      "50000/50000 [==============================] - 35s 708us/step - loss: 1.5973 - acc: 0.4158 - val_loss: 1.3711 - val_acc: 0.5074\n",
      "Epoch 3/250\n",
      "50000/50000 [==============================] - 36s 710us/step - loss: 1.4205 - acc: 0.4874 - val_loss: 1.1844 - val_acc: 0.5705\n",
      "Epoch 4/250\n",
      "50000/50000 [==============================] - 36s 711us/step - loss: 1.2968 - acc: 0.5338 - val_loss: 1.1551 - val_acc: 0.5944\n",
      "Epoch 5/250\n",
      "50000/50000 [==============================] - 36s 712us/step - loss: 1.2010 - acc: 0.5732 - val_loss: 1.0406 - val_acc: 0.6339\n",
      "Epoch 6/250\n",
      "50000/50000 [==============================] - 36s 711us/step - loss: 1.1174 - acc: 0.6044 - val_loss: 0.9980 - val_acc: 0.6509\n",
      "Epoch 7/250\n",
      "50000/50000 [==============================] - 36s 712us/step - loss: 1.0529 - acc: 0.6294 - val_loss: 0.9657 - val_acc: 0.6675\n",
      "Epoch 8/250\n",
      "50000/50000 [==============================] - 36s 712us/step - loss: 1.0059 - acc: 0.6453 - val_loss: 0.9029 - val_acc: 0.6857\n",
      "Epoch 9/250\n",
      "50000/50000 [==============================] - 36s 711us/step - loss: 0.9570 - acc: 0.6670 - val_loss: 0.8849 - val_acc: 0.6907\n",
      "Epoch 10/250\n",
      "50000/50000 [==============================] - 36s 711us/step - loss: 0.9159 - acc: 0.6795 - val_loss: 0.8360 - val_acc: 0.7086\n",
      "Epoch 11/250\n",
      "50000/50000 [==============================] - 36s 711us/step - loss: 0.8707 - acc: 0.6966 - val_loss: 0.7975 - val_acc: 0.7255\n",
      "Epoch 12/250\n",
      "50000/50000 [==============================] - 35s 710us/step - loss: 0.8468 - acc: 0.7033 - val_loss: 0.7933 - val_acc: 0.7229\n",
      "Epoch 13/250\n",
      "50000/50000 [==============================] - 35s 709us/step - loss: 0.8154 - acc: 0.7167 - val_loss: 0.7775 - val_acc: 0.7312\n",
      "Epoch 14/250\n",
      "50000/50000 [==============================] - 35s 709us/step - loss: 0.7835 - acc: 0.7267 - val_loss: 0.7742 - val_acc: 0.7301\n",
      "Epoch 15/250\n",
      "50000/50000 [==============================] - 35s 709us/step - loss: 0.7616 - acc: 0.7357 - val_loss: 0.7509 - val_acc: 0.7400\n",
      "Epoch 16/250\n",
      "50000/50000 [==============================] - 35s 709us/step - loss: 0.7294 - acc: 0.7471 - val_loss: 0.7385 - val_acc: 0.7455\n",
      "Epoch 17/250\n",
      "50000/50000 [==============================] - 35s 710us/step - loss: 0.7081 - acc: 0.7531 - val_loss: 0.6985 - val_acc: 0.7604\n",
      "Epoch 18/250\n",
      "50000/50000 [==============================] - 35s 710us/step - loss: 0.6903 - acc: 0.7596 - val_loss: 0.7208 - val_acc: 0.7533\n",
      "Epoch 19/250\n",
      "50000/50000 [==============================] - 35s 710us/step - loss: 0.6682 - acc: 0.7651 - val_loss: 0.6986 - val_acc: 0.7611\n",
      "Epoch 20/250\n",
      "50000/50000 [==============================] - 35s 710us/step - loss: 0.6464 - acc: 0.7730 - val_loss: 0.6903 - val_acc: 0.7652\n",
      "Epoch 21/250\n",
      "50000/50000 [==============================] - 36s 713us/step - loss: 0.6232 - acc: 0.7830 - val_loss: 0.6876 - val_acc: 0.7680\n",
      "Epoch 22/250\n",
      "50000/50000 [==============================] - 36s 712us/step - loss: 0.6035 - acc: 0.7885 - val_loss: 0.6644 - val_acc: 0.7745\n",
      "Epoch 23/250\n",
      "50000/50000 [==============================] - 36s 713us/step - loss: 0.5828 - acc: 0.7963 - val_loss: 0.6626 - val_acc: 0.7768\n",
      "Epoch 24/250\n",
      "50000/50000 [==============================] - 36s 711us/step - loss: 0.5655 - acc: 0.8022 - val_loss: 0.6524 - val_acc: 0.7747\n",
      "Epoch 25/250\n",
      "50000/50000 [==============================] - 36s 713us/step - loss: 0.5494 - acc: 0.8081 - val_loss: 0.6533 - val_acc: 0.7792\n",
      "Epoch 26/250\n",
      "50000/50000 [==============================] - 35s 710us/step - loss: 0.5374 - acc: 0.8114 - val_loss: 0.6704 - val_acc: 0.7772\n",
      "Epoch 27/250\n",
      "50000/50000 [==============================] - 35s 709us/step - loss: 0.5206 - acc: 0.8159 - val_loss: 0.6416 - val_acc: 0.7861\n",
      "Epoch 28/250\n",
      "50000/50000 [==============================] - 35s 709us/step - loss: 0.5103 - acc: 0.8214 - val_loss: 0.6521 - val_acc: 0.7830\n",
      "Epoch 29/250\n",
      "50000/50000 [==============================] - 36s 712us/step - loss: 0.4931 - acc: 0.8253 - val_loss: 0.6548 - val_acc: 0.7897\n",
      "Epoch 30/250\n",
      "50000/50000 [==============================] - 35s 710us/step - loss: 0.4763 - acc: 0.8307 - val_loss: 0.6658 - val_acc: 0.7869\n",
      "10000/10000 [==============================] - 3s 275us/step\n",
      "Loss: 0.666\n",
      "Accuracy: 0.787\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Load the dataset\n",
    "    (X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "\n",
    "    # Create the model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='selu', kernel_initializer='lecun_uniform'))\n",
    "    model.add(Dense(512, activation='selu', kernel_initializer='lecun_uniform'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    opt = Adam(lr=0.0001, decay=2e-6)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, to_categorical(Y_train),\n",
    "              batch_size=128,\n",
    "              shuffle=True,\n",
    "              epochs=250,\n",
    "              validation_data=(X_test, to_categorical(Y_test)),\n",
    "              callbacks=[EarlyStopping(min_delta=0.001, patience=3)])\n",
    "\n",
    "    # Evaluate the model\n",
    "    scores = model.evaluate(X_test, to_categorical(Y_test))\n",
    "\n",
    "    print('Loss: %.3f' % scores[0])\n",
    "print('Accuracy: %.3f' % scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 128)       3584      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,763,210\n",
      "Trainable params: 1,763,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"CIFAR10.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
